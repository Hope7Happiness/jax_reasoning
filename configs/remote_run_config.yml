training:
    batch_size: 768
    eval_batch_size: 768
    epochs: 100
    log_per_step: 400
    eval_interval: 10
    checkpoint_interval: 10

    optimizer: adam_atan2

model:
    name: HRM_default